{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Algorithms Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from os.path import dirname\n",
    "from networkx.drawing.nx_pydot import to_pydot\n",
    "\n",
    "# Import morpheus\n",
    "note_dir = os.getcwd()\n",
    "root_dir = dirname(note_dir)\n",
    "src_dir = os.path.join(root_dir, \"src\")\n",
    "\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "import morpheus\n",
    "\n",
    "from morpheus.tests import (default_dataset,\n",
    "                            default_m_list_for_mercs,\n",
    "                            random_m_list_for_mercs)\n",
    "\n",
    "from morpheus.graph import (model_to_graph)\n",
    "\n",
    "from morpheus.algo import (mi_algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_dot(g, dname='tmp', fname='test', extension='.dot', return_fname=True, ortho=False):\n",
    "    \"\"\"\n",
    "    Convert a graph to a dot file.\n",
    "    \"\"\"\n",
    "    \n",
    "    dot = nx.drawing.nx_pydot.to_pydot(g)\n",
    "    dot.set('rankdir', 'BT')\n",
    "    \n",
    "    if ortho:\n",
    "        dot.set('splines', 'ortho')\n",
    "    \n",
    "    full_fname = os.path.join(dname, fname+extension)\n",
    "    \n",
    "    print(full_fname)\n",
    "    \n",
    "    with open(full_fname, \"w\") as f:\n",
    "        print(dot.to_string, file=f)\n",
    "    \n",
    "    if return_fname:\n",
    "        return full_fname\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/test.dot\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/test.dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0c81f9d8e79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-bab1f35f84e1>\u001b[0m in \u001b[0;36mto_dot\u001b[0;34m(g, dname, fname, extension, return_fname, ortho)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/test.dot'"
     ]
    }
   ],
   "source": [
    "to_dot(g_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/lala.dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-0285b2c3189d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tmp/lala.dot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yah\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/lala.dot'"
     ]
    }
   ],
   "source": [
    "with open(\"tmp/lala.dot\", \"w\") as f:\n",
    "        print(\"yah\", file=f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from functools import reduce\n",
    "from os.path import dirname\n",
    "from networkx.drawing.nx_pydot import to_pydot\n",
    "\n",
    "note_dir = os.getcwd()\n",
    "\n",
    "root_dir = dirname(note_dir)\n",
    "src_dir = os.path.join(root_dir, \"src\")\n",
    "\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "\n",
    "import morpheus\n",
    "from morpheus.tests import (default_chain,\n",
    "                            default_ensemble,\n",
    "                            default_dataset,\n",
    "                            default_m_list_for_mercs,\n",
    "                            random_m_list_for_mercs)\n",
    "\n",
    "from morpheus.graph import (model_to_graph,\n",
    "                            model_graph_traces,\n",
    "                            model_graph_layout, \n",
    "                            convert_positions_to_dot_format,\n",
    "                            add_imputation_nodes,\n",
    "                            add_merge_nodes,\n",
    "                            fix_layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Basic Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Learning model with desc ids:    [0, 1, 2, 3, 4, 6, 7]\n",
      "                            targ ids:    [5]\n",
      "        \n",
      "\n",
      "        Learning model with desc ids:    [0, 1, 2, 3, 4, 5, 6]\n",
      "                            targ ids:    [7]\n",
      "        \n",
      "\n",
      "        Learning model with desc ids:    [0, 1, 2, 3, 4, 5, 7]\n",
      "                            targ ids:    [6]\n",
      "        \n",
      "\n",
      "        Learning model with desc ids:    [1, 2, 3, 4, 5, 6, 7]\n",
      "                            targ ids:    [0]\n",
      "        \n",
      "\n",
      "        Learning model with desc ids:    [0, 2, 3, 4, 5, 6, 7]\n",
      "                            targ ids:    [1]\n",
      "        \n",
      "\n",
      "        Learning model with desc ids:    [0, 1, 2, 4, 5, 6, 7]\n",
      "                            targ ids:    [3]\n",
      "        \n",
      "\n",
      "        Learning model with desc ids:    [0, 1, 3, 4, 5, 6, 7]\n",
      "                            targ ids:    [2]\n",
      "        \n",
      "\n",
      "        Learning model with desc ids:    [0, 1, 2, 3, 5, 6, 7]\n",
      "                            targ ids:    [4]\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "data, _ = default_dataset()\n",
    "data = data.values\n",
    "m_list = default_m_list_for_mercs(data)\n",
    "\n",
    "g_list = [model_to_graph(m, idx) for idx, m in enumerate(m_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI\n",
    "\n",
    "Testing our most basic prediction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_code = np.array([0,0,0,0,0,-1,1,1])\n",
    "g_res = mi_algorithm(g_list, q_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/mi.dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-50ca9a1023b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-920553bbeb9f>\u001b[0m in \u001b[0;36mto_dot\u001b[0;34m(g, dname, fname, extension, return_fname, ortho)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfull_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/mi.dot'"
     ]
    }
   ],
   "source": [
    "fname = to_dot(g_res, fname='mi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mi_algorithm(g_list, q_code):\n",
    "    \n",
    "    q_desc, q_targ, q_miss = code_to_query(q_code)\n",
    "    \n",
    "    def criterion(g):\n",
    "        outputs = set([g.nodes()[node]['idx'] for node, out_degree in g.out_degree()\n",
    "                       if out_degree == 0\n",
    "                       if g.nodes()[node]['kind']=='data'])\n",
    "        \n",
    "        \n",
    "        return len(set(q_targ).intersection(outputs)) > 0\n",
    "    \n",
    "    g_relevant = [g for g in g_list if criterion(g)]\n",
    "    g_relevant = [copy.deepcopy(g) for g in g_relevant]\n",
    "    \n",
    "    \n",
    "    g_relevant = [add_imputation_nodes(g, q_desc) for g in g_relevant]\n",
    "    \n",
    "    \n",
    "    result = reduce(nx.compose, g_relevant)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_list = Gs\n",
    "q_code = np.array([0,0,0,0,0,-1,1,1])\n",
    "g_res = mi_algorithm(g_list, q_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "X = to_pydot(g_res)\n",
    "X.set('rankdir', 'BT')\n",
    "#X.set('splines', 'ortho')\n",
    "\n",
    "with open(\"tmp/mi.dot\", \"w\") as text_file:\n",
    "    print(X.to_string(), file=text_file)\n",
    "\n",
    "!dot -T png ./tmp/mi.dot > ./tmp/mi.png  # Bash command\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "display(Image('tmp/mi.png', unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MA-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ma_algorithm(g_list, q_code, init_threshold=1.0, stepsize=0.1):\n",
    "    \n",
    "    q_desc, q_targ, q_miss = code_to_query(q_code)\n",
    "    \n",
    "    def criterion(g):\n",
    "        inputs = set([g.nodes()[node]['idx']\n",
    "                      for node, in_degree in g.in_degree()\n",
    "                      if in_degree == 0\n",
    "                      if g.nodes()[node]['kind']=='data'])\n",
    "        \n",
    "        outputs = set([g.nodes()[node]['idx']\n",
    "                       for node, out_degree in g.out_degree()\n",
    "                       if out_degree == 0\n",
    "                       if g.nodes()[node]['kind']=='data'])\n",
    "        \n",
    "        yes_no = len(set(q_targ).intersection(outputs)) > 0\n",
    "        \n",
    "        quantifier = len(set(q_desc).intersection(inputs))/len(inputs)\n",
    "        \n",
    "        result = int(yes_no) * quantifier\n",
    "        \n",
    "        msg = \"\"\"\n",
    "        yes_no:       {}\n",
    "        quantifier:   {}\n",
    "        result:       {}\n",
    "        \"\"\".format(yes_no, quantifier, result)\n",
    "        print(msg)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    thresholds = np.clip(np.arange(init_threshold, -stepsize, -stepsize), 0, 1)\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        g_relevant = [g for g in g_list if criterion(g) > thr]\n",
    "        if len(g_relevant) > 0:\n",
    "            print('we have found a model at threshold: {}'.format(thr))\n",
    "            break\n",
    "    \n",
    "    g_relevant = [copy.deepcopy(g) for g in g_relevant]\n",
    "    g_relevant = [add_imputation_nodes(g, q_desc) for g in g_relevant]\n",
    "    result = reduce(nx.compose, g_relevant)\n",
    "    \n",
    "    add_merge_nodes(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_list = random_m_list_for_mercs(data)\n",
    "m_list += random_m_list_for_mercs(data)\n",
    "\n",
    "Gs = [model_to_graph(m, idx) for idx, m in enumerate(m_list)]\n",
    "Gs = [fix_layout(g) for g in Gs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_code = np.array([-1,0,0,0,0,-1,1,0])\n",
    "g_res = ma_algorithm(Gs, q_code, init_threshold = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "X = to_pydot(g_res)\n",
    "X.set('rankdir', 'BT')\n",
    "#X.set('splines', 'ortho')\n",
    "\n",
    "with open(\"tmp/test.dot\", \"w\") as text_file:\n",
    "    print(X.to_string(), file=text_file)\n",
    "\n",
    "!dot -T png ./tmp/test.dot > ./tmp/test.png  # Bash command\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "display(Image('tmp/test.png', unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mrai_algorithm(g_list, q_code, init_threshold=1.0, stepsize=0.1):\n",
    "    \n",
    "    q_desc, q_targ, q_miss = code_to_query(q_code)\n",
    "    \n",
    "    def criterion(g):        \n",
    "        outputs = set([g.nodes()[node]['idx']\n",
    "                       for node, out_degree in g.out_degree()\n",
    "                       if out_degree == 0\n",
    "                       if g.nodes()[node]['kind']=='data'])\n",
    "        \n",
    "        yes_no = len(set(q_targ).intersection(outputs)) > 0\n",
    "        \n",
    "        feature_importances_available = [g.nodes()[node]['fi']\n",
    "                                         for node, in_degree in g.in_degree()\n",
    "                                         if in_degree == 0\n",
    "                                         if g.nodes()[node]['kind']=='data'\n",
    "                                         if g.nodes()[node]['idx'] in q_desc]\n",
    "        \n",
    "        quantifier = np.sum(feature_importances_available)\n",
    "        \n",
    "        result = int(yes_no) * quantifier\n",
    "        \n",
    "        msg = \"\"\"\n",
    "        yes_no:       {}\n",
    "        quantifier:   {}\n",
    "        result:       {}\n",
    "        \"\"\".format(yes_no, quantifier, result)\n",
    "        print(msg)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    thresholds = np.clip(np.arange(init_threshold, -stepsize, -stepsize), 0, 1)\n",
    "    \n",
    "    for thr in thresholds:\n",
    "        g_relevant = [g for g in g_list if criterion(g) > thr]\n",
    "        if len(g_relevant) > 0:\n",
    "            print('we have found a model at threshold: {}'.format(thr))\n",
    "            break\n",
    "    \n",
    "    g_relevant = [copy.deepcopy(g) for g in g_relevant]\n",
    "    g_relevant = [add_imputation_nodes(g, q_desc) for g in g_relevant]\n",
    "    result = reduce(nx.compose, g_relevant)\n",
    "    \n",
    "    add_merge_nodes(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_code = np.array([-1,0,0,0,0,-1,1,0])\n",
    "g_res = mrai_algorithm(Gs, q_code, init_threshold = 1, stepsize=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in g_res.edges():\n",
    "    g_res.edges()[e]['label'] = \"{0:.2f}\".format(g_res.edges()[e].get('fi', 0))\n",
    "\n",
    "# Plot\n",
    "X = to_pydot(g_res)\n",
    "X.set('rankdir', 'BT')\n",
    "#X.set('splines', 'ortho')\n",
    "\n",
    "with open(\"tmp/test.dot\", \"w\") as text_file:\n",
    "    print(X.to_string(), file=text_file)\n",
    "\n",
    "!dot -T png ./tmp/test.dot > ./tmp/test.png  # Bash command\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "display(Image('tmp/test.png', unconfined=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_extra = Gs[15].copy()\n",
    "g_extra.nodes()['d-05']['fi'] = g_extra.nodes()['d-05']['fi'] - 0.2\n",
    "g_extra.nodes()['d-03']['fi'] = g_extra.nodes()['d-03']['fi'] + 0.2\n",
    "\n",
    "Gs[15].nodes()['d-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_extra.nodes()['f-15'].rename('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_extra.nodes()['d-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gs.append(g_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:morpheus]",
   "language": "python",
   "name": "conda-env-morpheus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
