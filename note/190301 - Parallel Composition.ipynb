{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elia/Software/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from os.path import dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "note_dir = os.getcwd()\n",
    "root_dir = dirname(note_dir)\n",
    "data_dir = os.path.join(root_dir, 'resc', 'data', 'tidy','nltcs')\n",
    "\n",
    "# Filter relevant stuff out\n",
    "rel_fnames = [os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
    "              if 'F00' in f\n",
    "              if 'bayesfusion' not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fn, test_fn = rel_fnames[0], rel_fnames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get dfs\n",
    "df_train, df_test = pd.read_csv(train_fn, header=None), pd.read_csv(test_fn, header=None)\n",
    "\n",
    "# Get np.arrays\n",
    "train, test = df_train.values, df_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train some models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_rows, nb_atts = train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_codes = np.eye(nb_atts, dtype=np.int64)\n",
    "\n",
    "# Add second target\n",
    "for i in range(m_codes.shape[0]-1):\n",
    "    m_codes[i, i+1]=1\n",
    "\n",
    "m_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_model(m_code, train, **kwargs):\n",
    "    desc_ids, targ_ids = np.where(m_code==0)[0], np.where(m_code==1)[0]\n",
    "    X, Y = train[:, desc_ids], train[:, targ_ids]\n",
    "    \n",
    "    clf = RandomForestClassifier(**kwargs)\n",
    "    clf.desc_ids = desc_ids\n",
    "    clf.targ_ids = targ_ids\n",
    "    \n",
    "    if X.shape[1]==1: X = X.ravel()\n",
    "    if Y.shape[1]==1: Y = Y.ravel()\n",
    "\n",
    "    clf.fit(X,Y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_list = []\n",
    "for m_idx, m_code in enumerate(m_codes):\n",
    "    m_list.append(learn_model(m_code, train, max_depth=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_targ = np.array([1])\n",
    "q_desc = np.arange(6,16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So model 0 and 1 can predict our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_models = m_list[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_true = test[:, q_desc], test[:, q_targ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Composition\n",
    "\n",
    "A new, powerful way of combining models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MonoModel(object):\n",
    "    def fit(X, **kwargs):\n",
    "        return\n",
    "    \n",
    "    def predict(X, **kwargs):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     2,
     17,
     30,
     32,
     55,
     59,
     63,
     68,
     81,
     86,
     101,
     116,
     125,
     136,
     145,
     160
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParallelComposition(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.estimators = []\n",
    "        \n",
    "        self.desc_ids = np.array([])\n",
    "        self.targ_ids = np.array([])\n",
    "        \n",
    "        self.classes_ = [np.array([])]\n",
    "        \n",
    "        self.n_classes_ = 0\n",
    "        self.n_outputs_ = 0\n",
    "        self.n_features_ = 0\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fit(X, Y, **kwargs):\n",
    "        return\n",
    "    \n",
    "    def predict_proba(X, **kwargs):\n",
    "        nb_rows, nb_atts = X.shape\n",
    "        \n",
    "        s_proba = [np.zeros(nb_rows, n) for n in self.n_classes_]\n",
    "        \n",
    "        for e in self.estimators_:\n",
    "            e_proba = self._predict_proba_estimator(e, X, **kwargs)\n",
    "            s_proba = self._add_proba_estimator(e, e_proba, s_proba)\n",
    "        \n",
    "        # redo sklearn convention from hell\n",
    "        if len(s_proba) == 1:\n",
    "            return s_proba[0]\n",
    "        else:\n",
    "            return s_proba\n",
    "    \n",
    "    def predict(X, **kwargs):\n",
    "        nb_rows, nb_atts = X.shape\n",
    "        \n",
    "        s_pred = np.zeros(nb_rows, self.n_outputs)\n",
    "        \n",
    "        # redo sklearn convention from hell\n",
    "        if s_pred.shape[1] == 1:\n",
    "            return s_pred.ravel()\n",
    "        else:\n",
    "            return s_pred\n",
    "\n",
    "    # Updates (i.e., recalculate)\n",
    "    def _update_classes_(self):\n",
    "        # Re-initialize (easier)\n",
    "        self.classes_ = [np.array([])] * len(self.targ_ids)    \n",
    "        \n",
    "        for e in self.estimators_:\n",
    "            self._add_classes_estimator(e)\n",
    "        return\n",
    "    \n",
    "    def _update_n_classes_(self):\n",
    "        self.n_classes_ = [len(c) for c in self.classes_]\n",
    "        return \n",
    "    \n",
    "    def _update_n_outputs_(self):\n",
    "        self.n_outputs_ = len(self.targ_ids)\n",
    "        return \n",
    "    \n",
    "    def _update_n_features_(self):\n",
    "        self.n_features = len(self.desc_ids)\n",
    "        return \n",
    "    \n",
    "    # Add (i.e., incremental update)\n",
    "    def add_estimator(self, e):\n",
    "        self.estimators_.append(e)\n",
    "        \n",
    "        self._add_ids_estimator(e)\n",
    "\n",
    "        self._update_classes()\n",
    "        \n",
    "        self._update_n_classes_()\n",
    "        self._update_n_outputs_()\n",
    "        self._update_n_features_()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def _add_ids_estimator(self, e):\n",
    "        self.desc_ids = np.unique(np.concatenate((self.desc_ids, e.desc_ids)))\n",
    "        self.targ_ids = np.unique(np.concatenate((self.targ_ids, e.targ_ids)))\n",
    "        return\n",
    "    \n",
    "    def _add_classes_estimator(self, e):\n",
    "        \n",
    "        idx_map = self._map_elements_idx(e.targ_ids, self.targ_ids)\n",
    "        \n",
    "        def combine(classes_1, classes_2):\n",
    "            return np.unique(np.concatenate((classes_1, classes_2)))\n",
    "        \n",
    "        for idx_e, idx_s in idx_map:                    # `s` stands for `self`\n",
    "            e_classes_ = e.classes_[idx_e]\n",
    "            s_classes_ = self.classes_[idx_s]\n",
    "            \n",
    "            self.classes_[idx_s] = combine(e_classes_, s_classes_)\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def _add_proba_estimator(self, e, e_proba, s_proba):\n",
    "        \n",
    "        t_idx_map = self._map_elements_idx(e.targ_ids, self.targ_ids)\n",
    "        \n",
    "        for t_idx_e, t_idx_s in idx_map:                    # `s` stands for `self`\n",
    "            l_idx_map = self._map_elements_idx(e.classes_[t_idx_e], self.classes_[t_idx_s])\n",
    "            l_idx_map = np.array(l_idx_map)\n",
    "            \n",
    "            l_idx_e, l_idx_s = l_idx_map[:,0], l_idx_map[:,1]\n",
    "            \n",
    "            s_proba[idx_s][:, l_idx_s] += e_proba[t_idx_e][:, l_idx_e]\n",
    "            \n",
    "        return s_proba\n",
    "    \n",
    "    # Estimator - utilities\n",
    "    def _predict_estimator_tidy(self, e, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Ensure matrix.\n",
    "        \"\"\"\n",
    "        e_pred = e.predict(X, **kwargs)\n",
    "        \n",
    "        # undo sklearn convention from hell\n",
    "        return np.atleast_2d(e_pred)\n",
    "    \n",
    "    def _predict_proba_estimator_tidy(self, e, X, **kwargs):\n",
    "        \"\"\"\n",
    "        Ensure it is returned as a list.\n",
    "        \"\"\"\n",
    "        e_proba = e.predict_proba(X, **kwargs)\n",
    "        \n",
    "        # undo sklearn convention from hell\n",
    "        if isinstance(e_proba, np.ndarray):\n",
    "            return [e_proba]\n",
    "        elif isinstance(e_proba, list):\n",
    "            return e_proba\n",
    "        else:\n",
    "            msg = \"\"\"\n",
    "            e_proba has to be {np.ndarray, list},\n",
    "            instead the type was:   {}\n",
    "            \"\"\".format(type(e_proba))\n",
    "            raise TypeError(msg)\n",
    "            \n",
    "    \n",
    "    # Random utilities\n",
    "    def _map_elements_idx(self, a1, a2):\n",
    "        \"\"\"\n",
    "        Create a map that connects elements that occur in both arrays.\n",
    "\n",
    "        The output is a tuple list, with a tuple being;\n",
    "            (index of element e in a1, index of element e in a2)\n",
    "\n",
    "        N.b.:   Does not crash in case of double entries (behaviour is still correct),\n",
    "                but there are some ambiguities involved. I.e., do not do this.\n",
    "        \"\"\"\n",
    "        idx_a1 = np.where(np.in1d(a1, a2))[0]\n",
    "        idx_a2 = np.where(np.in1d(a2, a1))[0]\n",
    "\n",
    "        return list(zip(idx_a1, idx_a2))\n",
    "    \n",
    "    def filter_matrix(matrix, ids_1, ids_2):\n",
    "        \n",
    "        idx_map = np.array(self._map_elements_idx(ids_1, ids_2))\n",
    "        relevant_idx = idx_map[:, 0]\n",
    "        \n",
    "        if isinstance(matrix, np.ndarray):\n",
    "            # Case 1: Outcome of predict_proba of a single targets\n",
    "            # Case 2: Outcome of predict\n",
    "            return matrix[:, relevant_idx]\n",
    "        elif isinstance(matrix, list):\n",
    "            # Case 1: Outcome of predict_proba of a multiple targets\n",
    "            return [c for idx, c in enumerate(matrix) if idx in relevant_idx]\n",
    "        else:\n",
    "            msg = \"\"\"\n",
    "            Matrix has to be {np.ndarray, list},\n",
    "            instead the type was:   {}\n",
    "            \"\"\".format(type(matrix))\n",
    "            raise TypeError(msg)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.atleast_2d(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-854c961f0974>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-854c961f0974>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def consistent\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _map_elements_idx(self, a1, a2):\n",
    "    \"\"\"\n",
    "    Create a map that connects elements that occur in both arrays.\n",
    "\n",
    "    The output is a tuple list, with a tuple being;\n",
    "        (index of element e in a1, index of element e in a2)\n",
    "\n",
    "    N.b.:   Does not crash in case of double entries (behaviour is still correct),\n",
    "            but there are some ambiguities involved. I.e., do not do this.\n",
    "    \"\"\"\n",
    "    idx_a1 = np.where(np.in1d(a1, a2))[0]\n",
    "    idx_a2 = np.where(np.in1d(a2, a1))[0]\n",
    "\n",
    "    return list(zip(idx_a1, idx_a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_map_elements_idx(3, [1,2], [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_output(f, in_ids, out_ids):\n",
    "    \n",
    "    idx_map = _map_elements_idx(3, [1,2], [2])\n",
    "    \n",
    "    array = f()\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_two():\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alter_function(f):\n",
    "    return f() + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alter_function(get_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[0] = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11,
     29,
     35,
     54
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ParallelComposition(object):\n",
    "    \n",
    "    def __init__(self, estimators, targ_ids=None):\n",
    "        \n",
    "        # Estimators\n",
    "        self.estimators_ = estimators\n",
    "        \n",
    "        # Bookkeeping desc_ids/targ_ids\n",
    "        self.desc_ids = np.unique(np.concatenate([e.desc_ids for e in estimators]))\n",
    "        self.targ_ids = np.unique(np.concatenate([e.targ_ids for e in estimators]))\n",
    "        \n",
    "        if targ_ids is not None:\n",
    "            assert np.intersect1d(self.targ_ids, targ_ids).shape[0] > 0\n",
    "            self.targ_ids = targ_ids\n",
    "        \n",
    "        # Bookkeeping classes_\n",
    "        self.classes_ = [[]] * len(self.targ_ids)    # Init\n",
    "    \n",
    "        for e in self.estimators_:\n",
    "            self._add_classes_estimator(e)\n",
    "          \n",
    "        # n_classes_/n_outputs_/n_features_\n",
    "        self.n_classes_ = self.get_n_classes_()\n",
    "        self.n_outputs_ = self.get_n_outputs_() \n",
    "        self.n_features_ = self.get_n_features_()\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def get_n_classes_(self):\n",
    "        return [len(c) for c in self.classes_]\n",
    "    \n",
    "    def get_n_outputs_(self):\n",
    "        return len(self.targ_ids)\n",
    "    \n",
    "    def gen_n_features_(self):\n",
    "        return len(self.desc_ids)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _add_proba_estimator(self, e, e_proba, s_proba):\n",
    "        \n",
    "        t_idx_map = self._map_elements_idx(e.targ_ids, self.targ_ids)\n",
    "        \n",
    "        for t_idx_e, t_idx_s in idx_map:                    # `s` stands for `self`\n",
    "            l_idx_map = self._map_elements_idx(e.classes_[t_idx_e], self.classes_[t_idx_s])\n",
    "            l_idx_map = np.array(l_idx_map)\n",
    "            \n",
    "            l_idx_e, l_idx_s = l_idx_map[:,0], l_idx_map[:,1]\n",
    "            \n",
    "            s_proba[idx_s][:, l_idx_e] += e_proba[t_idx_e][:, l_idx_s]\n",
    "            \n",
    "        return s_proba\n",
    "    \n",
    "    def _add_classes_estimator(self, e):\n",
    "        \n",
    "        idx_map = self._map_elements_idx(e.targ_ids, self.targ_ids)\n",
    "        \n",
    "        def combine(classes_1, classes_2):\n",
    "            return np.unique(np.concatenate((classes_1, classes_2)))\n",
    "        \n",
    "        for idx_e, idx_s in idx_map:                    # `s` stands for `self`\n",
    "            e_classes_ = e.classes_[idx_e]\n",
    "            s_classes_ = self.classes_[idx_s]\n",
    "            \n",
    "            self.classes_[idx_s] = combine(e_classes_, s_classes_)\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def _map_elements_idx(self, a1, a2):\n",
    "        \"\"\"\n",
    "        Create a map that connects elements that occur in both arrays.\n",
    "\n",
    "        The output is a tuple list, with a tuple being;\n",
    "            (index of element e in a1, index of element e in a2)\n",
    "\n",
    "        N.b.:   Does not crash in case of double entries (behaviour is still correct),\n",
    "                but there are some ambiguities involved. I.e., do not do this.\n",
    "        \"\"\"\n",
    "        idx_a1 = np.where(np.in1d(a1, a2))[0]\n",
    "        idx_a2 = np.where(np.in1d(a2, a1))[0]\n",
    "\n",
    "        return list(zip(idx_a1, idx_a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_part = np.random.rand(40, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = np.zeros((40,3))\n",
    "template[:, [0,2]] = numeric_part\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_part = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal_part = np.zeros((40,2))\n",
    "nominal_part[:, [0]] = np.random.randint(0,2,size=(40,1))\n",
    "nominal_part[:, [1]] = np.random.randint(1,4,size=(40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = np.zeros((40,4))\n",
    "dataset[:, 0:2] = numeric_part\n",
    "dataset[:, 2:] = nominal_part\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc = ParallelComposition(rel_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.n_classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tl = [(1,2),(3,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(tl)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.targ_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.n_classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
